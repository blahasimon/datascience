{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Method 3: Neural network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "data": {
      "text/html": "        <script type=\"text/javascript\">\n        window.PlotlyConfig = {MathJaxConfig: 'local'};\n        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n        if (typeof require !== 'undefined') {\n        require.undef(\"plotly\");\n        requirejs.config({\n            paths: {\n                'plotly': ['https://cdn.plot.ly/plotly-2.4.2.min']\n            }\n        });\n        require(['plotly'], function(Plotly) {\n            window._Plotly = Plotly;\n        });\n        }\n        </script>\n        "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "import kaleido\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import numdifftools as nd\n",
    "from numpy.random import uniform\n",
    "import math as m\n",
    "import time\n",
    "from numba import jit\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split , KFold\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import warnings\n",
    "\n",
    "from collections import Counter\n",
    "# setup offline mode\n",
    "py.offline.init_notebook_mode(connected=True)\n",
    "\n",
    "pd.set_option('display.max_rows', 20)\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [],
   "source": [
    "CZ_ALPHABET = ['a', 'á', 'b', 'c', 'č', 'd', 'ď',\n",
    "               'e', 'é', 'ě', 'f', 'g', 'h', 'ch',\n",
    "               'i', 'í', 'j', 'k', 'l', 'm', 'n',\n",
    "               'ň', 'o', 'ó', 'p', 'q', 'r', 'ř',\n",
    "               's', 'š', 't', 'ť', 'u', 'ú','ů',\n",
    "               'v', 'w', 'x', 'y', 'ý','z', 'ž', ' ']\n",
    "\n",
    "def word_to_vector(word: str) -> np.array:\n",
    "    array = np.zeros(len(CZ_ALPHABET))\n",
    "    for i, alph in enumerate(CZ_ALPHABET):\n",
    "        array[i] = word.count(alph)\n",
    "    return pd.Series(array)\n",
    "\n",
    "def calculate_hidden_layer_size(Ns: int, Ni: int, No: int, alpha: int) -> float:\n",
    "    Nh = Ns / (alpha * (Ni - No))\n",
    "    return Nh\n",
    "\n",
    "def sigmoid(x):\n",
    "    y = 1 / (1 + np.e ** (-x))\n",
    "    return y\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    y = sigmoid(x) * (1 - sigmoid(x))\n",
    "    return y\n",
    "\n",
    "def ReLU(x):\n",
    "    y = x if x >= 0 else 0\n",
    "    return y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "data": {
      "text/plain": "       Obec                  Kraj    a    á    b    c    č    d    ď    e  \\\n0  abertamy      Karlovarský kraj  2.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0   \n1    adamov        Jihočeský kraj  2.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0   \n2    adamov     Jihomoravský kraj  2.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0   \n3    adamov      Středočeský kraj  2.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0   \n4  adršpach  Královéhradecký kraj  2.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0   \n\n   ...    ů    v    w    x    y    ý    z    ž       \\\n0  ...  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0   \n1  ...  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n2  ...  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n3  ...  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n4  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n\n                                     expected  \n0  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n1  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n2  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]  \n4  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]  \n\n[5 rows x 46 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Obec</th>\n      <th>Kraj</th>\n      <th>a</th>\n      <th>á</th>\n      <th>b</th>\n      <th>c</th>\n      <th>č</th>\n      <th>d</th>\n      <th>ď</th>\n      <th>e</th>\n      <th>...</th>\n      <th>ů</th>\n      <th>v</th>\n      <th>w</th>\n      <th>x</th>\n      <th>y</th>\n      <th>ý</th>\n      <th>z</th>\n      <th>ž</th>\n      <th></th>\n      <th>expected</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>abertamy</td>\n      <td>Karlovarský kraj</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>adamov</td>\n      <td>Jihočeský kraj</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>adamov</td>\n      <td>Jihomoravský kraj</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>adamov</td>\n      <td>Středočeský kraj</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>adršpach</td>\n      <td>Královéhradecký kraj</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 46 columns</p>\n</div>"
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data.csv', encoding = 'ansi', usecols=['Obec', 'Kraj'])\n",
    "data['Obec'] = data['Obec'].str.lower()\n",
    "output_dict = list(np.sort(data['Kraj'].unique()).flatten())\n",
    "\n",
    "data[CZ_ALPHABET] = data['Obec'].apply(word_to_vector)\n",
    "data['expected'] = data['Kraj'].apply(lambda x: (np.array(output_dict) == x).astype(int))\n",
    "\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Using the following to get the size of the hidden layer\n",
    "\n",
    "$$\n",
    "N_\\mathrm{h} = \\frac{N_\\mathrm{s}}{\\alpha (N_\\mathrm{i} + N_\\mathrm{o})}\n",
    "$$\n",
    "- $N_\\mathrm{s}$ - number of samples in training data\n",
    "- $N_\\mathrm{i}$ - number of input neurons (43)\n",
    "- $N_\\mathrm{o}$ - number of output neurons (14)\n",
    "- $\\alpha$ - an arbitrary number usually between 2 and 10"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "outputs": [],
   "source": [
    "class NN:\n",
    "    def __init__(self, size: np.array, func: str = 'sigmoid', x_train: np.ndarray = None,\n",
    "                 y_train: np.array = None, eta: float = 0.01, backpropagation: bool = False):\n",
    "\n",
    "        self.train = x_train\n",
    "        self.expected = y_train\n",
    "        self.size = size\n",
    "        self.func = func\n",
    "        self.eta = eta\n",
    "        self.backpropagation = backpropagation\n",
    "        self.layers = np.array([uniform(size=n) for n in size], dtype=object)\n",
    "\n",
    "        self.n_layers = len(size)\n",
    "\n",
    "        self.n_weights = np.dot(size[:-1], size[1:])\n",
    "        self.n_biases = np.sum(size[1:])\n",
    "\n",
    "        self.n_params = self.n_weights + self.n_biases\n",
    "        self.params = uniform(size=self.n_params)\n",
    "        # initialize weights\n",
    "        self.W = None\n",
    "        self.update_weights()\n",
    "        # initialize biases\n",
    "        self.B = None\n",
    "        self.update_biases()\n",
    "\n",
    "    def a(self, L: int, k: int):\n",
    "        if L == 0:\n",
    "            a = layers[0, k]\n",
    "        else:\n",
    "            a = sigmoid(self.z(L=L, k=k))\n",
    "        return a\n",
    "\n",
    "    def z(self, L: int, k: int):\n",
    "        z = np.dot(self.W[L-1, k] * self.layers[L-1]) + self.B[L-1, k]\n",
    "        return z\n",
    "\n",
    "    def w(self, L: int, i: int, j: int):\n",
    "        w = self.W[L-1][i, j]\n",
    "        return w\n",
    "\n",
    "    def b(self, L: int, k: int):\n",
    "        b = self.B[L-1, k]\n",
    "        return b\n",
    "\n",
    "    def update_weights(self):\n",
    "        weights = self.params[:self.n_weights]\n",
    "        lengths = [self.size[i] * self.size[i+1] for i in range(self.n_layers-1)]\n",
    "        slices = self.slice_from_lengths(lengths=lengths)\n",
    "        weights = np.split(weights, slices)[:-1]\n",
    "\n",
    "        for i in range(len(weights)):\n",
    "            newshape = (self.size[i+1], self.size[i])\n",
    "            weights[i] = weights[i].reshape(newshape)\n",
    "        self.W = weights\n",
    "\n",
    "    def update_biases(self):\n",
    "        biases = self.params[:self.n_biases]\n",
    "        lengths = self.size[1:]\n",
    "        slices = self.slice_from_lengths(lengths=lengths)\n",
    "        biases = np.split(biases, slices)\n",
    "        self.B = biases\n",
    "\n",
    "    def propagate_forward(self):\n",
    "        self.update_weights()\n",
    "        self.update_biases()\n",
    "        f = ReLU if self.func == 'ReLU' else sigmoid\n",
    "        for i in range(self.n_layers-1):\n",
    "            self.layers[i+1] = f(np.dot(self.W[i], self.layers[i]) + self.B[i])\n",
    "\n",
    "    def feed_input(self, layer0):\n",
    "        self.layers[0] = layer0\n",
    "\n",
    "    def get_output(self):\n",
    "        return self.layers[-1]\n",
    "\n",
    "    def slice_from_lengths(self, lengths):\n",
    "        slices = [np.sum(lengths[:i]) for i in range(self.n_layers)][1:]\n",
    "        return slices\n",
    "\n",
    "    def predict(self, vector: np.array):\n",
    "        if vector.shape[0] != self.size[0]:\n",
    "            print(f'Vector shape {vector.shape} does not match layer shape {self.size[0]}')\n",
    "            raise TypeError\n",
    "        self.feed_input(vector)\n",
    "        self.propagate_forward()\n",
    "        prediction = self.get_output()\n",
    "        return prediction\n",
    "\n",
    "    def predict_word(self, word: str):\n",
    "        vector = word_to_vector(word)\n",
    "        return self.predict(vector)\n",
    "\n",
    "    def cost(self, vector: np.array, expected: np.array):\n",
    "        prediction = self.predict(vector)\n",
    "        c = np.sum((prediction - expected) ** 2)\n",
    "        return c\n",
    "\n",
    "    def cost_of_sample(self, params: np.ndarray):\n",
    "        sample_size = len(self.train)\n",
    "        self.params = params\n",
    "        costs = np.array([self.cost(self.train[i], self.expected[i]) for i in range(sample_size)])\n",
    "        return np.mean(costs)\n",
    "\n",
    "    def neg_grad(self):\n",
    "        if self.backpropagation:\n",
    "            grad = 0\n",
    "        else:\n",
    "            grad = nd.Gradient(self.cost_of_sample)(self.params)\n",
    "        return -grad\n",
    "\n",
    "    def train_network(self):\n",
    "        neg_grad = self.neg_grad()\n",
    "        norm_factor = self.eta * np.linalg.norm(self.params) / np.linalg.norm(neg_grad)\n",
    "        self.params += norm_factor * neg_grad\n",
    "\n",
    "    def compute_accuracy(self, x_test: np.ndarray, y_test: np.ndarray):\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1., 0., 0., ..., 0., 0., 1.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [1., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [1., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]])"
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalizovat input!!!\n",
    "\n",
    "x = np.array(data[CZ_ALPHABET])\n",
    "y = np.array(data['expected'])\n",
    "\n",
    "X_TRAIN, X_TEST, Y_TRAIN, Y_TEST= train_test_split(x, y, test_size = 0.2, shuffle = True, random_state = 0)\n",
    "\n",
    "# normalize input?\n",
    "Ns = len(X_TRAIN)\n",
    "Ni = len(CZ_ALPHABET)\n",
    "No = len(output_dict)\n",
    "ALPHA = 5\n",
    "FUNC = 'sigmoid'\n",
    "ETA = 0.05\n",
    "N_ITER = 1\n",
    "\n",
    "X_TRAIN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the neural network with a sample of 5007 names.\n",
      "alpha = 5 → optimal hidden layer size: 35\n",
      "Initialising a neural network with shape (43, 35, 14)\n",
      "Activation function is set to sigmoid\n",
      "Learning rate is set to 0.05\n",
      "(35, 43)\n",
      "Starting learning session\n",
      "Cost before 12.999997076378664\n",
      "Currently at i = 0\r"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "hidden_layer_size = int(np.ceil(calculate_hidden_layer_size(Ns=Ns, Ni=Ni, No=No, alpha=ALPHA)))\n",
    "network_size = np.array([Ni, hidden_layer_size, No], dtype=object)\n",
    "\n",
    "\n",
    "print(f'Training the neural network with a sample of {Ns} names.')\n",
    "print(f'alpha = {ALPHA} → optimal hidden layer size: {hidden_layer_size}')\n",
    "print(f'Initialising a neural network with shape {(Ni, hidden_layer_size, No)}')\n",
    "print(f'Activation function is set to {FUNC}')\n",
    "print(f'Learning rate is set to {ETA}')\n",
    "\n",
    "\n",
    "network = NN(size=network_size, func=FUNC, x_train=X_TRAIN[:3], y_train=Y_TRAIN[:3], eta=ETA)\n",
    "\n",
    "print(network.W[0].shape)\n",
    "start = time.time()\n",
    "print('Starting learning session')\n",
    "# network.cost_of_sample(vector_sample=vector_sample, expected_sample=expected_sample)\n",
    "print('Cost before', network.cost_of_sample(network.params))\n",
    "\n",
    "for i in range(N_ITER):\n",
    "    s = time.time()\n",
    "    print(f'Currently at i = {i}', end='\\r')\n",
    "    network.train_network()\n",
    "    e = time.time()\n",
    "    print(f'Iteration took {e - s:.2f} seconds')\n",
    "\n",
    "print('Cost after', network.cost_of_sample(network.params))\n",
    "end = time.time()\n",
    "print(f'Finished in {end-start:.2f} seconds')\n",
    "\n",
    "# print(network.cost_of_sample(vector_sample=vector_sample, expected_sample=expected_sample))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [
    {
     "data": {
      "text/plain": "0.034350535229269855"
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['prediction'] = data['Obec'].apply(lambda x: output_dict[np.argmax(network.predict_word(word=x))])\n",
    "data['correct'] = data['Kraj'] == data['prediction']\n",
    "\n",
    "data['correct'].mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axisa: axis -1 is out of bounds for array of dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAxisError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [8], line 8\u001B[0m\n\u001B[0;32m      6\u001B[0m u \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray([\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m0\u001B[39m])\n\u001B[0;32m      7\u001B[0m v \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray([\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m0\u001B[39m])\n\u001B[1;32m----> 8\u001B[0m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[43mu\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mv\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\lib\\function_base.py:2163\u001B[0m, in \u001B[0;36mvectorize.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   2160\u001B[0m     vargs \u001B[38;5;241m=\u001B[39m [args[_i] \u001B[38;5;28;01mfor\u001B[39;00m _i \u001B[38;5;129;01min\u001B[39;00m inds]\n\u001B[0;32m   2161\u001B[0m     vargs\u001B[38;5;241m.\u001B[39mextend([kwargs[_n] \u001B[38;5;28;01mfor\u001B[39;00m _n \u001B[38;5;129;01min\u001B[39;00m names])\n\u001B[1;32m-> 2163\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_vectorize_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\lib\\function_base.py:2241\u001B[0m, in \u001B[0;36mvectorize._vectorize_call\u001B[1;34m(self, func, args)\u001B[0m\n\u001B[0;32m   2239\u001B[0m     res \u001B[38;5;241m=\u001B[39m func()\n\u001B[0;32m   2240\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 2241\u001B[0m     ufunc, otypes \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_ufunc_and_otypes\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2243\u001B[0m     \u001B[38;5;66;03m# Convert args to object arrays first\u001B[39;00m\n\u001B[0;32m   2244\u001B[0m     inputs \u001B[38;5;241m=\u001B[39m [asanyarray(a, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mobject\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m a \u001B[38;5;129;01min\u001B[39;00m args]\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\lib\\function_base.py:2201\u001B[0m, in \u001B[0;36mvectorize._get_ufunc_and_otypes\u001B[1;34m(self, func, args)\u001B[0m\n\u001B[0;32m   2197\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcannot call `vectorize` on size 0 inputs \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m   2198\u001B[0m                      \u001B[38;5;124m'\u001B[39m\u001B[38;5;124munless `otypes` is set\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m   2200\u001B[0m inputs \u001B[38;5;241m=\u001B[39m [arg\u001B[38;5;241m.\u001B[39mflat[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m arg \u001B[38;5;129;01min\u001B[39;00m args]\n\u001B[1;32m-> 2201\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2203\u001B[0m \u001B[38;5;66;03m# Performance note: profiling indicates that -- for simple\u001B[39;00m\n\u001B[0;32m   2204\u001B[0m \u001B[38;5;66;03m# functions at least -- this wrapping can almost double the\u001B[39;00m\n\u001B[0;32m   2205\u001B[0m \u001B[38;5;66;03m# execution time.\u001B[39;00m\n\u001B[0;32m   2206\u001B[0m \u001B[38;5;66;03m# Hence we make it optional.\u001B[39;00m\n\u001B[0;32m   2207\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcache:\n",
      "Cell \u001B[1;32mIn [7], line 2\u001B[0m, in \u001B[0;36mfunction\u001B[1;34m(u, v)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfunction\u001B[39m(u: np\u001B[38;5;241m.\u001B[39marray, v:np\u001B[38;5;241m.\u001B[39marray):\n\u001B[1;32m----> 2\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcross\u001B[49m\u001B[43m(\u001B[49m\u001B[43mu\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mv\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m<__array_function__ internals>:5\u001B[0m, in \u001B[0;36mcross\u001B[1;34m(*args, **kwargs)\u001B[0m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\numeric.py:1597\u001B[0m, in \u001B[0;36mcross\u001B[1;34m(a, b, axisa, axisb, axisc, axis)\u001B[0m\n\u001B[0;32m   1595\u001B[0m b \u001B[38;5;241m=\u001B[39m asarray(b)\n\u001B[0;32m   1596\u001B[0m \u001B[38;5;66;03m# Check axisa and axisb are within bounds\u001B[39;00m\n\u001B[1;32m-> 1597\u001B[0m axisa \u001B[38;5;241m=\u001B[39m \u001B[43mnormalize_axis_index\u001B[49m\u001B[43m(\u001B[49m\u001B[43maxisa\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43ma\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mndim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmsg_prefix\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43maxisa\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1598\u001B[0m axisb \u001B[38;5;241m=\u001B[39m normalize_axis_index(axisb, b\u001B[38;5;241m.\u001B[39mndim, msg_prefix\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maxisb\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m   1600\u001B[0m \u001B[38;5;66;03m# Move working axis to the end of the shape\u001B[39;00m\n",
      "\u001B[1;31mAxisError\u001B[0m: axisa: axis -1 is out of bounds for array of dimension 0"
     ]
    }
   ],
   "source": [
    "def function(u: np.array, v:np.array):\n",
    "    return np.cross(u, v)\n",
    "\n",
    "function(np.array([1, 0]), np.array([0, 1]))\n",
    "\n",
    "u = np.array([1, 0, 0])\n",
    "v = np.array([0, 1, 0])\n",
    "f(u, v)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "array([1., 1., 1.])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(u, v):\n",
    "    return u + v\n",
    "\n",
    "u = np.array([0, 0, 0])\n",
    "v = np.array([1, 2, 3])\n",
    "\n",
    "np.diagonal(nd.Gradient(f)(u, v))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
