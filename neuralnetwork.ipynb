{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Method 3: Neural network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/html": "        <script type=\"text/javascript\">\n        window.PlotlyConfig = {MathJaxConfig: 'local'};\n        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n        if (typeof require !== 'undefined') {\n        require.undef(\"plotly\");\n        requirejs.config({\n            paths: {\n                'plotly': ['https://cdn.plot.ly/plotly-2.4.2.min']\n            }\n        });\n        require(['plotly'], function(Plotly) {\n            window._Plotly = Plotly;\n        });\n        }\n        </script>\n        "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "import kaleido\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import numdifftools as nd\n",
    "from numpy.random import uniform\n",
    "import math as m\n",
    "import time\n",
    "from numba import jit\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split , KFold\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import warnings\n",
    "\n",
    "from collections import Counter\n",
    "# setup offline mode\n",
    "py.offline.init_notebook_mode(connected=True)\n",
    "\n",
    "pd.set_option('display.max_rows', 20)\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "CZ_ALPHABET = ['a', 'á', 'b', 'c', 'č', 'd', 'ď',\n",
    "               'e', 'é', 'ě', 'f', 'g', 'h', 'ch',\n",
    "               'i', 'í', 'j', 'k', 'l', 'm', 'n',\n",
    "               'ň', 'o', 'ó', 'p', 'q', 'r', 'ř',\n",
    "               's', 'š', 't', 'ť', 'u', 'ú','ů',\n",
    "               'v', 'w', 'x', 'y', 'ý','z', 'ž', ' ']\n",
    "\n",
    "def word_to_vector(word: str) -> np.array:\n",
    "    array = np.zeros(len(CZ_ALPHABET))\n",
    "    for i, alph in enumerate(CZ_ALPHABET):\n",
    "        array[i] = word.count(alph)\n",
    "    return pd.Series(array)\n",
    "\n",
    "def calculate_hidden_layer_size(Ns: int, Ni: int, No: int, alpha: int) -> float:\n",
    "    Nh = Ns / (alpha * (Ni - No))\n",
    "    return Nh\n",
    "\n",
    "def sigmoid(x):\n",
    "    y = 1 / (1 + np.e ** (-x))\n",
    "    return y\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    y = sigmoid(x) * (1 - sigmoid(x))\n",
    "    return y\n",
    "\n",
    "def ReLU(x):\n",
    "    y = x if x >= 0 else 0\n",
    "    return y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "       Obec                  Kraj    a    á    b    c    č    d    ď    e  \\\n0  abertamy      Karlovarský kraj  2.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0   \n1    adamov        Jihočeský kraj  2.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0   \n2    adamov     Jihomoravský kraj  2.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0   \n3    adamov      Středočeský kraj  2.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0   \n4  adršpach  Královéhradecký kraj  2.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0   \n\n   ...    ů    v    w    x    y    ý    z    ž       \\\n0  ...  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0   \n1  ...  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n2  ...  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n3  ...  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n4  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n\n                                     expected  \n0  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n1  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n2  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]  \n4  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]  \n\n[5 rows x 46 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Obec</th>\n      <th>Kraj</th>\n      <th>a</th>\n      <th>á</th>\n      <th>b</th>\n      <th>c</th>\n      <th>č</th>\n      <th>d</th>\n      <th>ď</th>\n      <th>e</th>\n      <th>...</th>\n      <th>ů</th>\n      <th>v</th>\n      <th>w</th>\n      <th>x</th>\n      <th>y</th>\n      <th>ý</th>\n      <th>z</th>\n      <th>ž</th>\n      <th></th>\n      <th>expected</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>abertamy</td>\n      <td>Karlovarský kraj</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>adamov</td>\n      <td>Jihočeský kraj</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>adamov</td>\n      <td>Jihomoravský kraj</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>adamov</td>\n      <td>Středočeský kraj</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>adršpach</td>\n      <td>Královéhradecký kraj</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 46 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data.csv', encoding = 'ansi', usecols=['Obec', 'Kraj'])\n",
    "data['Obec'] = data['Obec'].str.lower()\n",
    "output_dict = list(np.sort(data['Kraj'].unique()).flatten())\n",
    "\n",
    "data[CZ_ALPHABET] = data['Obec'].apply(word_to_vector)\n",
    "data['expected'] = data['Kraj'].apply(lambda x: (np.array(output_dict) == x).astype(int))\n",
    "\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Using the following to get the size of the hidden layer\n",
    "\n",
    "$$\n",
    "N_\\mathrm{h} = \\frac{N_\\mathrm{s}}{\\alpha (N_\\mathrm{i} + N_\\mathrm{o})}\n",
    "$$\n",
    "- $N_\\mathrm{s}$ - number of samples in training data\n",
    "- $N_\\mathrm{i}$ - number of input neurons (43)\n",
    "- $N_\\mathrm{o}$ - number of output neurons (14)\n",
    "- $\\alpha$ - an arbitrary number usually between 2 and 10"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class NN:\n",
    "    def __init__(self, size: np.array, func: str = 'sigmoid', x_train: np.ndarray = None,\n",
    "                 y_train: np.array = None, eta: float = 0.01, backpropagation: bool = False):\n",
    "\n",
    "        self.train = x_train\n",
    "        self.expected = y_train\n",
    "        self.size = size\n",
    "        self.func = func\n",
    "        self.eta = eta\n",
    "        self.backpropagation = backpropagation\n",
    "        self.layers = np.array([uniform(size=n) for n in size], dtype=object)\n",
    "\n",
    "        self.n_layers = len(size)\n",
    "\n",
    "        self.n_weights = np.dot(size[:-1], size[1:])\n",
    "        self.n_biases = np.sum(size[1:])\n",
    "\n",
    "        self.n_params = self.n_weights + self.n_biases\n",
    "        self.params = uniform(size=self.n_params)\n",
    "        # initialize weights\n",
    "        self.W = None\n",
    "        self.update_weights()\n",
    "        # initialize biases\n",
    "        self.B = None\n",
    "        self.update_biases()\n",
    "\n",
    "    def a(self, L: int, k: int):\n",
    "        if L == 0:\n",
    "            a = layers[0, k]\n",
    "        else:\n",
    "            a = sigmoid(self.z(L=L, k=k))\n",
    "        return a\n",
    "\n",
    "    def z(self, L: int, k: int):\n",
    "        z = np.dot(self.W[L-1, k] * self.layers[L-1]) + self.B[L-1, k]\n",
    "        return z\n",
    "\n",
    "    def w(self, L: int, i: int, j: int):\n",
    "        w = self.W[L-1][i, j]\n",
    "        return w\n",
    "\n",
    "    def b(self, L: int, k: int):\n",
    "        b = self.B[L-1, k]\n",
    "        return b\n",
    "\n",
    "    def update_weights(self):\n",
    "        weights = self.params[:self.n_weights]\n",
    "        lengths = [self.size[i] * self.size[i+1] for i in range(self.n_layers-1)]\n",
    "        slices = self.slice_from_lengths(lengths=lengths)\n",
    "        weights = np.split(weights, slices)[:-1]\n",
    "\n",
    "        for i in range(len(weights)):\n",
    "            newshape = (self.size[i+1], self.size[i])\n",
    "            weights[i] = weights[i].reshape(newshape)\n",
    "        self.W = weights\n",
    "\n",
    "    def update_biases(self):\n",
    "        biases = self.params[:self.n_biases]\n",
    "        lengths = self.size[1:]\n",
    "        slices = self.slice_from_lengths(lengths=lengths)\n",
    "        biases = np.split(biases, slices)\n",
    "        self.B = biases\n",
    "\n",
    "    def propagate_forward(self):\n",
    "        self.update_weights()\n",
    "        self.update_biases()\n",
    "        f = ReLU if self.func == 'ReLU' else sigmoid\n",
    "        for i in range(self.n_layers-1):\n",
    "            self.layers[i+1] = f(np.dot(self.W[i], self.layers[i]) + self.B[i])\n",
    "\n",
    "    def feed_input(self, layer0):\n",
    "        self.layers[0] = layer0\n",
    "\n",
    "    def get_output(self):\n",
    "        return self.layers[-1]\n",
    "\n",
    "    def slice_from_lengths(self, lengths):\n",
    "        slices = [np.sum(lengths[:i]) for i in range(self.n_layers)][1:]\n",
    "        return slices\n",
    "\n",
    "    def predict(self, vector: np.array):\n",
    "        if vector.shape[0] != self.size[0]:\n",
    "            print(f'Vector shape {vector.shape} does not match layer shape {self.size[0]}')\n",
    "            raise TypeError\n",
    "        self.feed_input(vector)\n",
    "        self.propagate_forward()\n",
    "        prediction = self.get_output()\n",
    "        return prediction\n",
    "\n",
    "    def predict_word(self, word: str):\n",
    "        vector = word_to_vector(word)\n",
    "        return self.predict(vector)\n",
    "\n",
    "    def cost(self, vector: np.array, expected: np.array):\n",
    "        prediction = self.predict(vector)\n",
    "        c = np.sum((prediction - expected) ** 2)\n",
    "        return c\n",
    "\n",
    "    def cost_of_sample(self, params: np.ndarray):\n",
    "        sample_size = len(self.train)\n",
    "        self.params = params\n",
    "        costs = np.array([self.cost(self.train[i], self.expected[i]) for i in range(sample_size)])\n",
    "        return np.mean(costs)\n",
    "\n",
    "    def neg_grad(self):\n",
    "        if self.backpropagation:\n",
    "            grad = 0\n",
    "        else:\n",
    "            grad = nd.Gradient(self.cost_of_sample)(self.params)\n",
    "        return -grad\n",
    "\n",
    "    # functions for backpropagation\n",
    "    def d_l(self, l: int):\n",
    "        if l == self.n_layers - 1:\n",
    "            d_l = np.multiply(self.dE_dA(l), self.dA_dZ(l))\n",
    "        else:\n",
    "            d_l = np.dot(self.d_l(l+1).T, self.W[l])\n",
    "            d_l = np.multiply(d_l, self.dA_dZ(l))\n",
    "        return d_l\n",
    "\n",
    "    def X(self, l: int):\n",
    "        return self.layers[l]\n",
    "\n",
    "    def dE_dA(self, l: int):\n",
    "        if l == self.n_layers - 1:\n",
    "            pass\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    def dA_dZ(self, l: int):\n",
    "        pass\n",
    "\n",
    "    def dE_dW(self, l: int):\n",
    "        dE_dW = np.multiply(self.d_l(l), self.X(l-1))\n",
    "        return dE_dW\n",
    "\n",
    "    def train_network(self):\n",
    "        neg_grad = self.neg_grad()\n",
    "        norm_factor = self.eta * np.linalg.norm(self.params) / np.linalg.norm(neg_grad)\n",
    "        self.params += norm_factor * neg_grad\n",
    "\n",
    "    def compute_accuracy(self, x_test: np.ndarray, y_test: np.ndarray):\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1., 0., 0., ..., 0., 0., 1.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [1., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [1., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalizovat input!!!\n",
    "\n",
    "x = np.array(data[CZ_ALPHABET])\n",
    "y = np.array(data['expected'])\n",
    "\n",
    "X_TRAIN, X_TEST, Y_TRAIN, Y_TEST= train_test_split(x, y, test_size = 0.2, shuffle = True, random_state = 0)\n",
    "\n",
    "# normalize input?\n",
    "Ns = len(X_TRAIN)\n",
    "Ni = len(CZ_ALPHABET)\n",
    "No = len(output_dict)\n",
    "ALPHA = 5\n",
    "FUNC = 'sigmoid'\n",
    "ETA = 0.05\n",
    "N_ITER = 8\n",
    "\n",
    "X_TRAIN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [8], line 25\u001B[0m\n\u001B[0;32m     23\u001B[0m s \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCurrently at i = \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m, end\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\r\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m---> 25\u001B[0m \u001B[43mnetwork\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_network\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     26\u001B[0m e \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m     27\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mIteration took \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me \u001B[38;5;241m-\u001B[39m s\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.2f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m seconds\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "Cell \u001B[1;32mIn [6], line 138\u001B[0m, in \u001B[0;36mNN.train_network\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    137\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtrain_network\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m--> 138\u001B[0m     neg_grad \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mneg_grad\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    139\u001B[0m     norm_factor \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39meta \u001B[38;5;241m*\u001B[39m np\u001B[38;5;241m.\u001B[39mlinalg\u001B[38;5;241m.\u001B[39mnorm(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparams) \u001B[38;5;241m/\u001B[39m np\u001B[38;5;241m.\u001B[39mlinalg\u001B[38;5;241m.\u001B[39mnorm(neg_grad)\n\u001B[0;32m    140\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparams \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m norm_factor \u001B[38;5;241m*\u001B[39m neg_grad\n",
      "Cell \u001B[1;32mIn [6], line 109\u001B[0m, in \u001B[0;36mNN.neg_grad\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    107\u001B[0m     grad \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m    108\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 109\u001B[0m     grad \u001B[38;5;241m=\u001B[39m \u001B[43mnd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mGradient\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcost_of_sample\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    110\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;241m-\u001B[39mgrad\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numdifftools\\core.py:490\u001B[0m, in \u001B[0;36mGradient.__call__\u001B[1;34m(self, x, *args, **kwds)\u001B[0m\n\u001B[0;32m    489\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, x, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds):\n\u001B[1;32m--> 490\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msuper\u001B[39m(Gradient, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m(np\u001B[38;5;241m.\u001B[39matleast_1d(x)\u001B[38;5;241m.\u001B[39mravel(), \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    491\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfull_output:\n\u001B[0;32m    492\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m result[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39msqueeze(), result[\u001B[38;5;241m1\u001B[39m]\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numdifftools\\core.py:431\u001B[0m, in \u001B[0;36mJacobian.__call__\u001B[1;34m(self, x, *args, **kwds)\u001B[0m\n\u001B[0;32m    430\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, x, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds):\n\u001B[1;32m--> 431\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m(Jacobian, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m(np\u001B[38;5;241m.\u001B[39matleast_1d(x), \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numdifftools\\core.py:288\u001B[0m, in \u001B[0;36mDerivative.__call__\u001B[1;34m(self, x, *args, **kwds)\u001B[0m\n\u001B[0;32m    286\u001B[0m x_i \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray(x)\n\u001B[0;32m    287\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m np\u001B[38;5;241m.\u001B[39merrstate(divide\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m'\u001B[39m, invalid\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[1;32m--> 288\u001B[0m     results, f_xi \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_derivative\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_i\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    289\u001B[0m     derivative, info \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_extrapolate(\u001B[38;5;241m*\u001B[39mresults)\n\u001B[0;32m    290\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfull_output:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numdifftools\\core.py:423\u001B[0m, in \u001B[0;36mJacobian._derivative_nonzero_order\u001B[1;34m(self, x_i, args, kwds)\u001B[0m\n\u001B[0;32m    421\u001B[0m steps, step_ratio \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_steps(x_i)\n\u001B[0;32m    422\u001B[0m fxi \u001B[38;5;241m=\u001B[39m f(x_i)\n\u001B[1;32m--> 423\u001B[0m results \u001B[38;5;241m=\u001B[39m [diff(f, fxi, x_i, h) \u001B[38;5;28;01mfor\u001B[39;00m h \u001B[38;5;129;01min\u001B[39;00m steps]\n\u001B[0;32m    425\u001B[0m steps2 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_expand_steps(steps, x_i, fxi)\n\u001B[0;32m    427\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mset_richardson_rule(step_ratio, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrichardson_terms)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numdifftools\\core.py:423\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    421\u001B[0m steps, step_ratio \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_steps(x_i)\n\u001B[0;32m    422\u001B[0m fxi \u001B[38;5;241m=\u001B[39m f(x_i)\n\u001B[1;32m--> 423\u001B[0m results \u001B[38;5;241m=\u001B[39m [\u001B[43mdiff\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfxi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx_i\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mh\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m h \u001B[38;5;129;01min\u001B[39;00m steps]\n\u001B[0;32m    425\u001B[0m steps2 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_expand_steps(steps, x_i, fxi)\n\u001B[0;32m    427\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mset_richardson_rule(step_ratio, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrichardson_terms)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numdifftools\\finite_difference.py:122\u001B[0m, in \u001B[0;36mJacobianDifferenceFunctions._central\u001B[1;34m(f, f_x, x, h)\u001B[0m\n\u001B[0;32m    120\u001B[0m n \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(x)\n\u001B[0;32m    121\u001B[0m steps \u001B[38;5;241m=\u001B[39m JacobianDifferenceFunctions\u001B[38;5;241m.\u001B[39mincrements(n, h)\n\u001B[1;32m--> 122\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39marray([(f(x \u001B[38;5;241m+\u001B[39m hi) \u001B[38;5;241m-\u001B[39m f(x \u001B[38;5;241m-\u001B[39m hi)) \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2.0\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m hi \u001B[38;5;129;01min\u001B[39;00m steps])\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numdifftools\\finite_difference.py:122\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    120\u001B[0m n \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(x)\n\u001B[0;32m    121\u001B[0m steps \u001B[38;5;241m=\u001B[39m JacobianDifferenceFunctions\u001B[38;5;241m.\u001B[39mincrements(n, h)\n\u001B[1;32m--> 122\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39marray([(f(x \u001B[38;5;241m+\u001B[39m hi) \u001B[38;5;241m-\u001B[39m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mhi\u001B[49m\u001B[43m)\u001B[49m) \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2.0\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m hi \u001B[38;5;129;01min\u001B[39;00m steps])\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numdifftools\\core.py:257\u001B[0m, in \u001B[0;36mDerivative._get_functions.<locals>.export_fun\u001B[1;34m(x)\u001B[0m\n\u001B[0;32m    256\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mexport_fun\u001B[39m(x):\n\u001B[1;32m--> 257\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fun(x, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n",
      "Cell \u001B[1;32mIn [6], line 102\u001B[0m, in \u001B[0;36mNN.cost_of_sample\u001B[1;34m(self, params)\u001B[0m\n\u001B[0;32m    100\u001B[0m sample_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain)\n\u001B[0;32m    101\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparams \u001B[38;5;241m=\u001B[39m params\n\u001B[1;32m--> 102\u001B[0m costs \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray([\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcost(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain[i], \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexpected[i]) \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(sample_size)])\n\u001B[0;32m    103\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39mmean(costs)\n",
      "Cell \u001B[1;32mIn [6], line 102\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    100\u001B[0m sample_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain)\n\u001B[0;32m    101\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparams \u001B[38;5;241m=\u001B[39m params\n\u001B[1;32m--> 102\u001B[0m costs \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray([\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcost\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexpected\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(sample_size)])\n\u001B[0;32m    103\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39mmean(costs)\n",
      "Cell \u001B[1;32mIn [6], line 95\u001B[0m, in \u001B[0;36mNN.cost\u001B[1;34m(self, vector, expected)\u001B[0m\n\u001B[0;32m     94\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcost\u001B[39m(\u001B[38;5;28mself\u001B[39m, vector: np\u001B[38;5;241m.\u001B[39marray, expected: np\u001B[38;5;241m.\u001B[39marray):\n\u001B[1;32m---> 95\u001B[0m     prediction \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvector\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     96\u001B[0m     c \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39msum((prediction \u001B[38;5;241m-\u001B[39m expected) \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m \u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m     97\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m c\n",
      "Cell \u001B[1;32mIn [6], line 86\u001B[0m, in \u001B[0;36mNN.predict\u001B[1;34m(self, vector)\u001B[0m\n\u001B[0;32m     84\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m\n\u001B[0;32m     85\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeed_input(vector)\n\u001B[1;32m---> 86\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpropagate_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     87\u001B[0m prediction \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_output()\n\u001B[0;32m     88\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m prediction\n",
      "Cell \u001B[1;32mIn [6], line 69\u001B[0m, in \u001B[0;36mNN.propagate_forward\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     67\u001B[0m f \u001B[38;5;241m=\u001B[39m ReLU \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunc \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mReLU\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m sigmoid\n\u001B[0;32m     68\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_layers\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m):\n\u001B[1;32m---> 69\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayers[i\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m=\u001B[39m f(\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdot\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mW\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlayers\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mB[i])\n",
      "File \u001B[1;32m<__array_function__ internals>:5\u001B[0m, in \u001B[0;36mdot\u001B[1;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "hidden_layer_size = int(np.ceil(calculate_hidden_layer_size(Ns=Ns, Ni=Ni, No=No, alpha=ALPHA)))\n",
    "network_size = np.array([Ni, hidden_layer_size, No], dtype=object)\n",
    "\n",
    "\n",
    "print(f'Training the neural network with a sample of {Ns} names.')\n",
    "print(f'alpha = {ALPHA} → optimal hidden layer size: {hidden_layer_size}')\n",
    "print(f'Initialising a neural network with shape {(Ni, hidden_layer_size, No)}')\n",
    "print(f'Activation function is set to {FUNC}')\n",
    "print(f'Learning rate is set to {ETA}')\n",
    "\n",
    "\n",
    "network = NN(size=network_size, func=FUNC, x_train=X_TRAIN[:700], y_train=Y_TRAIN[:700], eta=ETA, backpropagation=False)\n",
    "\n",
    "print(network.W[0].shape)\n",
    "start = time.time()\n",
    "print('Starting learning session')\n",
    "# network.cost_of_sample(vector_sample=vector_sample, expected_sample=expected_sample)\n",
    "print('Cost before', network.cost_of_sample(network.params))\n",
    "\n",
    "for i in range(N_ITER):\n",
    "    s = time.time()\n",
    "    print(f'Currently at i = {i}', end='\\r')\n",
    "    network.train_network()\n",
    "    e = time.time()\n",
    "    print(f'Iteration took {e - s:.2f} seconds')\n",
    "\n",
    "print('Cost after', network.cost_of_sample(network.params))\n",
    "end = time.time()\n",
    "print(f'Finished in {end-start:.2f} seconds')\n",
    "\n",
    "# print(network.cost_of_sample(vector_sample=vector_sample, expected_sample=expected_sample))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data['prediction'] = data['Obec'].apply(lambda x: output_dict[np.argmax(network.predict_word(word=x))])\n",
    "data['is_correct'] = data['Kraj'] == data['prediction']\n",
    "\n",
    "data['is_correct'].mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "arr = np.tile([1, 2, 3], (3, 1))\n",
    "arr.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "shape = [43, 25, 14]\n",
    "n_weights = np.dot(shape[1:], shape[:-1])\n",
    "weights = np.random.uniform(size=n_weights)\n",
    "\n",
    "indeces = np.cumsum(np.multiply(shape[1:], shape[:-1]))\n",
    "\n",
    "weights = np.split(weights, indeces)[:-1]\n",
    "print(len(weights))\n",
    "for layer in weights:\n",
    "    print(layer.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "total = 0\n",
    "def row_sum(x, y):\n",
    "    row_sum = x + y\n",
    "    global total\n",
    "    total += row_sum\n",
    "    return row_sum\n",
    "\n",
    "df = pd.DataFrame({\"A\": [1, 2, 3],\n",
    "                   \"B\": [3, 4, 5]\n",
    "                   })\n",
    "\n",
    "df.apply(lambda row: row_sum(row[0], row[1]), axis=1)\n",
    "print(total)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "0           Karlovarský kraj\n1             Jihočeský kraj\n2          Jihomoravský kraj\n3           Středočeský kraj\n4       Královéhradecký kraj\n                ...         \n6254        Karlovarský kraj\n6255          Olomoucký kraj\n6256         Pardubický kraj\n6257          Jihočeský kraj\n6258        Středočeský kraj\nName: Kraj, Length: 6259, dtype: object"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[:, 1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_dict = {\n",
    "    sigmoid: ReLU\n",
    "}\n",
    "\n",
    "func_dict[sigmoid](-5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "povídání matematika\n"
     ]
    }
   ],
   "source": [
    "activities = ['kreslení', 'povídání', 'předvádění']\n",
    "subjects = ['matematika', 'fyzika']\n",
    "i_a = np.random.randint(0, 3)\n",
    "i_s = np.random.randint(0, 2)\n",
    "print(activities[i_a], subjects[i_s])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "[[array([0.90775354, 0.36902822, 0.14569077, 0.17580159, 0.37288331,\n         0.6992771 , 0.98591966, 0.98977379, 0.51281808, 0.02207219,\n         0.83584847, 0.68306341, 0.5965872 , 0.69454343, 0.11882914,\n         0.91503272, 0.38663549, 0.56692535, 0.30788714, 0.35795568,\n         0.56077635, 0.99669272, 0.62804393, 0.99720054, 0.61373387,\n         0.49082924, 0.67636714, 0.55717322, 0.24304509, 0.09580556,\n         0.10558262, 0.57676409, 0.05534122, 0.34439121, 0.8314402 ,\n         0.73389861, 0.86338317, 0.36381457, 0.07317685, 0.18910632,\n         0.58109321, 0.39700182, 0.75520731]),\n  array([0.45218832, 0.48980106, 0.32087086, 0.73056332, 0.53754062,\n         0.20997717, 0.90594164, 0.88067984, 0.42494239, 0.17382308,\n         0.41773399, 0.95456796, 0.45323998])],\n [array([0.88481045, 0.9883843 , 0.84970419, 0.56138503, 0.6599603 ,\n         0.44406562, 0.08959943, 0.57333434, 0.47983568, 0.68514501,\n         0.38133234, 0.92544897, 0.37488609, 0.88327933, 0.2966762 ,\n         0.08881507, 0.40205023, 0.67247848, 0.65806321, 0.98278223,\n         0.10038217, 0.30333623, 0.76152154, 0.57084185, 0.13966824,\n         0.87347881, 0.39542349, 0.41666163, 0.07891711, 0.05930204,\n         0.59358232, 0.41896305, 0.7658279 , 0.89652317, 0.16702991,\n         0.74314775, 0.97310574, 0.79994464, 0.83074255, 0.32604288,\n         0.4595382 , 0.29192417, 0.65833171]),\n  array([0.1704165 , 0.70651608, 0.11419165, 0.47391225, 0.01719018,\n         0.84373084, 0.3178127 , 0.44284544, 0.54266896, 0.13227565,\n         0.70427005, 0.82913842, 0.60017056])],\n [array([0.52175124, 0.56083933, 0.87678828, 0.61502918, 0.10897822,\n         0.93263696, 0.89336643, 0.24527885, 0.10369471, 0.06560446,\n         0.10596779, 0.73559446, 0.35172907, 0.10257746, 0.72718314,\n         0.78678678, 0.9850007 , 0.31875102, 0.69167109, 0.25482301,\n         0.25113377, 0.12180162, 0.83072929, 0.02202566, 0.60288039,\n         0.21946748, 0.02550615, 0.63966984, 0.43712606, 0.94921805,\n         0.53842547, 0.36169013, 0.31625554, 0.05122974, 0.72093552,\n         0.91371518, 0.5978944 , 0.76405311, 0.27588491, 0.12256614,\n         0.55251829, 0.27395103, 0.94515458]),\n  array([0.53289251, 0.00625854, 0.7792348 , 0.41585005, 0.50455118,\n         0.04692278, 0.65063749, 0.47172044, 0.07177576, 0.16629363,\n         0.34568269, 0.3233324 , 0.06879643])],\n [array([0.29555948, 0.87831967, 0.62890566, 0.39628986, 0.79751805,\n         0.21009049, 0.90906812, 0.53708099, 0.94097   , 0.532606  ,\n         0.42983404, 0.16175463, 0.28146145, 0.87792588, 0.30338695,\n         0.41969803, 0.86601513, 0.632204  , 0.58747138, 0.89567254,\n         0.42246192, 0.25198661, 0.96670312, 0.45875006, 0.52274326,\n         0.0556993 , 0.64049491, 0.68205462, 0.02010849, 0.87657181,\n         0.40276132, 0.88418194, 0.48728334, 0.08262776, 0.23606175,\n         0.1721752 , 0.55466109, 0.74985479, 0.42637745, 0.36013885,\n         0.81373949, 0.506631  , 0.54303968]),\n  array([0.53289251, 0.00625854, 0.7792348 , 0.41585005, 0.50455118,\n         0.04692278, 0.65063749, 0.47172044, 0.07177576, 0.16629363,\n         0.34568269, 0.3233324 , 0.06879643])]]"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "muffin = np.random.uniform(size=43)\n",
    "pizza = np.random.uniform(size=43)\n",
    "kebab = np.random.uniform(size=43)\n",
    "apple = np.random.uniform(size=43)\n",
    "\n",
    "exp1, exp2, exp3 = np.random.uniform(size=13), np.random.uniform(size=13), np.random.uniform(size=13)\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'food': (muffin, pizza, kebab, apple),\n",
    "    'expected': (exp1, exp2, exp3, exp3)\n",
    "})\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
