{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Method 3: Neural network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "data": {
      "text/html": "        <script type=\"text/javascript\">\n        window.PlotlyConfig = {MathJaxConfig: 'local'};\n        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n        if (typeof require !== 'undefined') {\n        require.undef(\"plotly\");\n        requirejs.config({\n            paths: {\n                'plotly': ['https://cdn.plot.ly/plotly-2.4.2.min']\n            }\n        });\n        require(['plotly'], function(Plotly) {\n            window._Plotly = Plotly;\n        });\n        }\n        </script>\n        "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "import kaleido\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import numdifftools as nd\n",
    "from numpy.random import uniform\n",
    "import math as m\n",
    "import time\n",
    "from numba import jit\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split , KFold\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import warnings\n",
    "\n",
    "from collections import Counter\n",
    "# setup offline mode\n",
    "py.offline.init_notebook_mode(connected=True)\n",
    "\n",
    "pd.set_option('display.max_rows', 20)\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [],
   "source": [
    "CZ_ALPHABET = ['a', 'á', 'b', 'c', 'č', 'd', 'ď',\n",
    "               'e', 'é', 'ě', 'f', 'g', 'h', 'ch',\n",
    "               'i', 'í', 'j', 'k', 'l', 'm', 'n',\n",
    "               'ň', 'o', 'ó', 'p', 'q', 'r', 'ř',\n",
    "               's', 'š', 't', 'ť', 'u', 'ú','ů',\n",
    "               'v', 'w', 'x', 'y', 'ý','z', 'ž', ' ']\n",
    "\n",
    "def word_to_vector(word: str) -> np.array:\n",
    "    array = np.zeros(len(CZ_ALPHABET))\n",
    "    for i, alph in enumerate(CZ_ALPHABET):\n",
    "        array[i] = word.count(alph)\n",
    "    return pd.Series(array)\n",
    "\n",
    "def calculate_hidden_layer_size(Ns: int, Ni: int, No: int, alpha: int) -> float:\n",
    "    Nh = Ns / (alpha * (Ni - No))\n",
    "    return Nh\n",
    "\n",
    "def sigmoid(x):\n",
    "    y = 1 / (1 + np.e ** (-x))\n",
    "    return y\n",
    "\n",
    "def ReLU(x):\n",
    "    y = x if x >= 0 else 0\n",
    "    return y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "data": {
      "text/plain": "       Obec                  Kraj    a    á    b    c    č    d    ď    e  \\\n0  abertamy      Karlovarský kraj  2.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0   \n1    adamov        Jihočeský kraj  2.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0   \n2    adamov     Jihomoravský kraj  2.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0   \n3    adamov      Středočeský kraj  2.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0   \n4  adršpach  Královéhradecký kraj  2.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0   \n\n   ...    ů    v    w    x    y    ý    z    ž       \\\n0  ...  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0   \n1  ...  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n2  ...  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n3  ...  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n4  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n\n                                     expected  \n0  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n1  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n2  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]  \n4  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]  \n\n[5 rows x 46 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Obec</th>\n      <th>Kraj</th>\n      <th>a</th>\n      <th>á</th>\n      <th>b</th>\n      <th>c</th>\n      <th>č</th>\n      <th>d</th>\n      <th>ď</th>\n      <th>e</th>\n      <th>...</th>\n      <th>ů</th>\n      <th>v</th>\n      <th>w</th>\n      <th>x</th>\n      <th>y</th>\n      <th>ý</th>\n      <th>z</th>\n      <th>ž</th>\n      <th></th>\n      <th>expected</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>abertamy</td>\n      <td>Karlovarský kraj</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>adamov</td>\n      <td>Jihočeský kraj</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>adamov</td>\n      <td>Jihomoravský kraj</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>adamov</td>\n      <td>Středočeský kraj</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>adršpach</td>\n      <td>Královéhradecký kraj</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 46 columns</p>\n</div>"
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data.csv', encoding = 'ansi', usecols=['Obec', 'Kraj'])\n",
    "data['Obec'] = data['Obec'].str.lower()\n",
    "output_dict = list(np.sort(data['Kraj'].unique()).flatten())\n",
    "\n",
    "data[CZ_ALPHABET] = data['Obec'].apply(word_to_vector)\n",
    "data['expected'] = data['Kraj'].apply(lambda x: (np.array(output_dict) == x).astype(int))\n",
    "\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Using the following to get the size of the hidden layer\n",
    "\n",
    "$$\n",
    "N_\\mathrm{h} = \\frac{N_\\mathrm{s}}{\\alpha (N_\\mathrm{i} + N_\\mathrm{o})}\n",
    "$$\n",
    "- $N_\\mathrm{s}$ - number of samples in training data\n",
    "- $N_\\mathrm{i}$ - number of input neurons (43)\n",
    "- $N_\\mathrm{o}$ - number of output neurons (14)\n",
    "- $\\alpha$ - an arbitrary number usually between 2 and 10"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "The decorated object is not a function (got type <class 'type'>).",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [110], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;129;43m@jit\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mnopython\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m \n\u001B[1;32m----> 3\u001B[0m \u001B[38;5;28;43;01mclass\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;21;43;01mNN\u001B[39;49;00m\u001B[43m:\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mdef\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msize\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43marray\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43msigmoid\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_sample\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mndarray\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m                 \u001B[49m\u001B[43mexpected_sample\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43marray\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meta\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mfloat\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtrain_sample\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mexpected_sample\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m:\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numba\\core\\decorators.py:198\u001B[0m, in \u001B[0;36m_jit.<locals>.wrapper\u001B[1;34m(func)\u001B[0m\n\u001B[0;32m    191\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[0;32m    192\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mA jit decorator was called on an already jitted function \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    193\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.  If trying to access the original python \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    194\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfunction, use the \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.py_func attribute.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    195\u001B[0m     )\n\u001B[0;32m    197\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m inspect\u001B[38;5;241m.\u001B[39misfunction(func):\n\u001B[1;32m--> 198\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[0;32m    199\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe decorated object is not a function (got type \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    200\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(func)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m).\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    201\u001B[0m     )\n\u001B[0;32m    203\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m config\u001B[38;5;241m.\u001B[39mENABLE_CUDASIM \u001B[38;5;129;01mand\u001B[39;00m target \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m    204\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mnumba\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m cuda\n",
      "\u001B[1;31mTypeError\u001B[0m: The decorated object is not a function (got type <class 'type'>)."
     ]
    }
   ],
   "source": [
    "class NN:\n",
    "    def __init__(self, size: np.array, func: str = 'sigmoid', train_sample: np.ndarray = None,\n",
    "                 expected_sample: np.array = None, eta: float = 0.01):\n",
    "        if train_sample is None or expected_sample is None:\n",
    "            print('Check training and expected data: None was passed!')\n",
    "        self.train = train_sample\n",
    "        self.expected = expected_sample\n",
    "        self.size = size\n",
    "        self.func = func\n",
    "        self.eta = eta\n",
    "        self.layers = np.array([uniform(size=n) for n in size], dtype=object)\n",
    "\n",
    "        self.n_layers = len(size)\n",
    "\n",
    "        self.n_weights = np.dot(size[:-1], size[1:])\n",
    "        self.n_biases = np.sum(size[1:])\n",
    "\n",
    "        self.n_params = self.n_weights + self.n_biases\n",
    "        self.params = uniform(size=self.n_params)\n",
    "        # initialize weights\n",
    "        self.W = None\n",
    "        self.weights()\n",
    "        # initialize biases\n",
    "        self.b = None\n",
    "        self.biases()\n",
    "        # self.biases = np.array([uniform(size=n) for n in size[1:]], dtype=object)\n",
    "\n",
    "    def weights(self):\n",
    "        weights = self.params[:self.n_weights]\n",
    "        lengths = [self.size[i] * self.size[i+1] for i in range(self.n_layers-1)]\n",
    "        slices = self.slice_from_lengths(lengths=lengths)\n",
    "        weights = np.split(weights, slices)[:-1]\n",
    "\n",
    "        for i in range(len(weights)):\n",
    "            newshape = (self.size[i+1], self.size[i])\n",
    "            weights[i] = weights[i].reshape(newshape)\n",
    "        self.W = weights\n",
    "\n",
    "    def biases(self):\n",
    "        biases = self.params[:self.n_biases]\n",
    "        lengths = self.size[1:]\n",
    "        slices = self.slice_from_lengths(lengths=lengths)\n",
    "        biases = np.split(biases, slices)\n",
    "        self.b = biases\n",
    "\n",
    "    def propagate_forward(self):\n",
    "        self.weights()\n",
    "        self.biases()\n",
    "        f = ReLU if self.func == 'ReLU' else sigmoid\n",
    "        for i in range(self.n_layers-1):\n",
    "            self.layers[i+1] = f(np.dot(self.W[i], self.layers[i]) + self.b[i])\n",
    "\n",
    "    def feed_input(self, layer0):\n",
    "        self.layers[0] = layer0\n",
    "\n",
    "    def get_output(self):\n",
    "        return self.layers[-1]\n",
    "\n",
    "    def slice_from_lengths(self, lengths):\n",
    "        slices = [np.sum(lengths[:i]) for i in range(self.n_layers)][1:]\n",
    "        return slices\n",
    "\n",
    "    def predict(self, vector: np.array):\n",
    "        if vector.shape[0] != self.size[0]:\n",
    "            print(f'Vector shape {vector.shape} does not match layer shape {self.size[0]}')\n",
    "            raise TypeError\n",
    "        self.feed_input(vector)\n",
    "        self.propagate_forward()\n",
    "        prediction = self.get_output()\n",
    "        return prediction\n",
    "\n",
    "    def predict_word(self, word: str):\n",
    "        vector = word_to_vector(word)\n",
    "        return self.predict(vector)\n",
    "\n",
    "    def cost(self, vector: np.array, expected: np.array):\n",
    "        prediction = self.predict(vector)\n",
    "        c = np.sum((prediction - expected) ** 2)\n",
    "        return c\n",
    "\n",
    "    def cost_of_sample(self, params: np.ndarray):\n",
    "        sample_size = len(self.train)\n",
    "        self.params = params\n",
    "        costs = np.array([self.cost(self.train[i], self.expected[i]) for i in range(sample_size)])\n",
    "        return np.mean(costs)\n",
    "\n",
    "    def neg_grad(self):\n",
    "        grad = nd.Gradient(self.cost_of_sample)(self.params)\n",
    "        return -grad\n",
    "\n",
    "    def train_network(self):\n",
    "        neg_grad = self.neg_grad()\n",
    "        norm_factor = self.eta * np.linalg.norm(self.params) / np.linalg.norm(neg_grad)\n",
    "        self.params += norm_factor * neg_grad"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [],
   "source": [
    "x = data['Obec']\n",
    "y = data[CZ_ALPHABET]\n",
    "\n",
    "x_train, x_test, y_train, y_test= train_test_split(x, y,\n",
    "                                                   test_size = 0.2,\n",
    "                                                   shuffle = True,\n",
    "                                                   random_state = 0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the neural network with a sample of 5007 names.\n",
      "alpha = 5 → optimal hidden layer size: 35\n",
      "Initialising a neural network with shape (43, 35, 14)\n",
      "Activation function is set to sigmoid\n",
      "train_sample.shape (100, 43)\n",
      "expected_sample.shape (100,)\n",
      "starting\n",
      "Cost before 12.999995974091487\n",
      "Currently at i = 0\r"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'norm'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [105], line 35\u001B[0m\n\u001B[0;32m     33\u001B[0m s \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m     34\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCurrently at i = \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m, end\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\r\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m---> 35\u001B[0m \u001B[43mnetwork\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_network\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     36\u001B[0m e \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m     37\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mIteration took \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me \u001B[38;5;241m-\u001B[39m s\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m:.2f seconds\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "Cell \u001B[1;32mIn [103], line 93\u001B[0m, in \u001B[0;36mNN.train_network\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     91\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtrain_network\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m     92\u001B[0m     neg_grad \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mneg_grad()\n\u001B[1;32m---> 93\u001B[0m     norm_factor \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39meta \u001B[38;5;241m*\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnorm\u001B[49m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparams) \u001B[38;5;241m/\u001B[39m np\u001B[38;5;241m.\u001B[39mnorm(neg_grad)\n\u001B[0;32m     94\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparams \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m norm_factor \u001B[38;5;241m*\u001B[39m neg_grad\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\__init__.py:313\u001B[0m, in \u001B[0;36m__getattr__\u001B[1;34m(attr)\u001B[0m\n\u001B[0;32m    310\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtesting\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Tester\n\u001B[0;32m    311\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m Tester\n\u001B[1;32m--> 313\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodule \u001B[39m\u001B[38;5;132;01m{!r}\u001B[39;00m\u001B[38;5;124m has no attribute \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    314\u001B[0m                      \u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{!r}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;18m__name__\u001B[39m, attr))\n",
      "\u001B[1;31mAttributeError\u001B[0m: module 'numpy' has no attribute 'norm'"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "Ns = len(x_train)\n",
    "Ni = len(CZ_ALPHABET)\n",
    "No = len(output_dict)\n",
    "ALPHA = 5\n",
    "FUNC = 'sigmoid'\n",
    "SAMPLE_SIZE = 100\n",
    "\n",
    "hidden_layer_size = int(np.ceil(calculate_hidden_layer_size(Ns=Ns, Ni=Ni, No=No, alpha=ALPHA)))\n",
    "network_size = np.array([Ni, hidden_layer_size, No], dtype=object)\n",
    "train_sample = np.array(data[CZ_ALPHABET])[:SAMPLE_SIZE]\n",
    "expected_sample = np.array(data['expected'])[:SAMPLE_SIZE]\n",
    "\n",
    "print(f'Training the neural network with a sample of {Ns} names.')\n",
    "print(f'alpha = {ALPHA} → optimal hidden layer size: {hidden_layer_size}')\n",
    "print(f'Initialising a neural network with shape {(Ni, hidden_layer_size, No)}')\n",
    "print(f'Activation function is set to {FUNC}')\n",
    "\n",
    "network = NN(size=network_size, func=FUNC, train_sample=train_sample, expected_sample=expected_sample)\n",
    "\n",
    "WORD = 'Beroun'\n",
    "word_vector = word_to_vector(WORD)\n",
    "#network.predict_word(word='Zdařilá Víska')\n",
    "\n",
    "print('train_sample.shape', train_sample.shape)\n",
    "print('expected_sample.shape', expected_sample.shape)\n",
    "start = time.time()\n",
    "print('starting')\n",
    "# network.cost_of_sample(vector_sample=vector_sample, expected_sample=expected_sample)\n",
    "print('Cost before', network.cost_of_sample(network.params))\n",
    "for i in range(100):\n",
    "    s = time.time()\n",
    "    print(f'Currently at i = {i}', end='\\r')\n",
    "    network.train_network()\n",
    "    e = time.time()\n",
    "    print(f'Iteration took {e - s}:.2f seconds')\n",
    "print('Cost after', network.cost_of_sample(network.params))\n",
    "end = time.time()\n",
    "print('Finished in', end-start)\n",
    "print('Average time per row:', round((end-start) / SAMPLE_SIZE, 3), 'seconds. ')\n",
    "\n",
    "print(f'Predicting {WORD}: {output_dict[np.argmax(network.predict_word(word=WORD))]}')\n",
    "\n",
    "# print(network.cost_of_sample(vector_sample=vector_sample, expected_sample=expected_sample))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [
    {
     "data": {
      "text/plain": "0.05655855567982106"
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['prediction'] = data['Obec'].apply(lambda x: output_dict[np.argmax(network.predict_word(word=x))])\n",
    "data['correct'] = data['Kraj'] == data['prediction']\n",
    "\n",
    "data['correct'].mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axisa: axis -1 is out of bounds for array of dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAxisError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [8], line 8\u001B[0m\n\u001B[0;32m      6\u001B[0m u \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray([\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m0\u001B[39m])\n\u001B[0;32m      7\u001B[0m v \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray([\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m0\u001B[39m])\n\u001B[1;32m----> 8\u001B[0m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[43mu\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mv\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\lib\\function_base.py:2163\u001B[0m, in \u001B[0;36mvectorize.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   2160\u001B[0m     vargs \u001B[38;5;241m=\u001B[39m [args[_i] \u001B[38;5;28;01mfor\u001B[39;00m _i \u001B[38;5;129;01min\u001B[39;00m inds]\n\u001B[0;32m   2161\u001B[0m     vargs\u001B[38;5;241m.\u001B[39mextend([kwargs[_n] \u001B[38;5;28;01mfor\u001B[39;00m _n \u001B[38;5;129;01min\u001B[39;00m names])\n\u001B[1;32m-> 2163\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_vectorize_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\lib\\function_base.py:2241\u001B[0m, in \u001B[0;36mvectorize._vectorize_call\u001B[1;34m(self, func, args)\u001B[0m\n\u001B[0;32m   2239\u001B[0m     res \u001B[38;5;241m=\u001B[39m func()\n\u001B[0;32m   2240\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 2241\u001B[0m     ufunc, otypes \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_ufunc_and_otypes\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2243\u001B[0m     \u001B[38;5;66;03m# Convert args to object arrays first\u001B[39;00m\n\u001B[0;32m   2244\u001B[0m     inputs \u001B[38;5;241m=\u001B[39m [asanyarray(a, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mobject\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m a \u001B[38;5;129;01min\u001B[39;00m args]\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\lib\\function_base.py:2201\u001B[0m, in \u001B[0;36mvectorize._get_ufunc_and_otypes\u001B[1;34m(self, func, args)\u001B[0m\n\u001B[0;32m   2197\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcannot call `vectorize` on size 0 inputs \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m   2198\u001B[0m                      \u001B[38;5;124m'\u001B[39m\u001B[38;5;124munless `otypes` is set\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m   2200\u001B[0m inputs \u001B[38;5;241m=\u001B[39m [arg\u001B[38;5;241m.\u001B[39mflat[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m arg \u001B[38;5;129;01min\u001B[39;00m args]\n\u001B[1;32m-> 2201\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2203\u001B[0m \u001B[38;5;66;03m# Performance note: profiling indicates that -- for simple\u001B[39;00m\n\u001B[0;32m   2204\u001B[0m \u001B[38;5;66;03m# functions at least -- this wrapping can almost double the\u001B[39;00m\n\u001B[0;32m   2205\u001B[0m \u001B[38;5;66;03m# execution time.\u001B[39;00m\n\u001B[0;32m   2206\u001B[0m \u001B[38;5;66;03m# Hence we make it optional.\u001B[39;00m\n\u001B[0;32m   2207\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcache:\n",
      "Cell \u001B[1;32mIn [7], line 2\u001B[0m, in \u001B[0;36mfunction\u001B[1;34m(u, v)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfunction\u001B[39m(u: np\u001B[38;5;241m.\u001B[39marray, v:np\u001B[38;5;241m.\u001B[39marray):\n\u001B[1;32m----> 2\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcross\u001B[49m\u001B[43m(\u001B[49m\u001B[43mu\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mv\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m<__array_function__ internals>:5\u001B[0m, in \u001B[0;36mcross\u001B[1;34m(*args, **kwargs)\u001B[0m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\numeric.py:1597\u001B[0m, in \u001B[0;36mcross\u001B[1;34m(a, b, axisa, axisb, axisc, axis)\u001B[0m\n\u001B[0;32m   1595\u001B[0m b \u001B[38;5;241m=\u001B[39m asarray(b)\n\u001B[0;32m   1596\u001B[0m \u001B[38;5;66;03m# Check axisa and axisb are within bounds\u001B[39;00m\n\u001B[1;32m-> 1597\u001B[0m axisa \u001B[38;5;241m=\u001B[39m \u001B[43mnormalize_axis_index\u001B[49m\u001B[43m(\u001B[49m\u001B[43maxisa\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43ma\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mndim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmsg_prefix\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43maxisa\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1598\u001B[0m axisb \u001B[38;5;241m=\u001B[39m normalize_axis_index(axisb, b\u001B[38;5;241m.\u001B[39mndim, msg_prefix\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maxisb\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m   1600\u001B[0m \u001B[38;5;66;03m# Move working axis to the end of the shape\u001B[39;00m\n",
      "\u001B[1;31mAxisError\u001B[0m: axisa: axis -1 is out of bounds for array of dimension 0"
     ]
    }
   ],
   "source": [
    "def function(u: np.array, v:np.array):\n",
    "    return np.cross(u, v)\n",
    "\n",
    "function(np.array([1, 0]), np.array([0, 1]))\n",
    "\n",
    "u = np.array([1, 0, 0])\n",
    "v = np.array([0, 1, 0])\n",
    "f(u, v)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "array([1., 1., 1.])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(u, v):\n",
    "    return u + v\n",
    "\n",
    "u = np.array([0, 0, 0])\n",
    "v = np.array([1, 2, 3])\n",
    "\n",
    "np.diagonal(nd.Gradient(f)(u, v))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
